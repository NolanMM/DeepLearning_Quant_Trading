{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e86daf8-e0cb-4767-bb8a-f8cf46a10fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql import SparkSession\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "postgres_v = os.getenv(\"POSTGRES_VERSION\")\n",
    "postgres_url = os.getenv(\"POSTGRES_URL\")\n",
    "postgres_user = os.getenv(\"POSTGRES_USER\")\n",
    "postgres_pass = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "postgres_table = os.getenv(\"POSTGRES_TABLE\")\n",
    "format_file = os.getenv(\"FORMAT_FILE\")\n",
    "_mode = os.getenv(\"MODE\")\n",
    "\n",
    "config_ = postgres_v\n",
    "\n",
    "column_1_name = os.getenv(\"COLUMN_1\")\n",
    "column_2_name = os.getenv(\"COLUMN_2\")\n",
    "column_3_name = os.getenv(\"COLUMN_3\")\n",
    "column_4_name = os.getenv(\"COLUMN_4\")\n",
    "column_5_name = os.getenv(\"COLUMN_5\")\n",
    "column_6_name = os.getenv(\"COLUMN_6\")\n",
    "column_7_name = os.getenv(\"COLUMN_7\")\n",
    "column_8_name = os.getenv(\"COLUMN_8\")\n",
    "\n",
    "list_remove = ['GEV','SOLV','VLTO','BF.B','BRK.B']\n",
    "\n",
    "class ListSAndP500:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the ListSAndP500 class\n",
    "\n",
    "        Attributes:\n",
    "        tickers_string (list): A list of stock symbols in string format\n",
    "        tickers_list (list): A list of stock symbols in list format\n",
    "\n",
    "        \"\"\"\n",
    "        _tickers = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "        _tickers = _tickers.Symbol.to_list()\n",
    "        self.tickers_string = [i.replace('.','-') for i in _tickers]\n",
    "        _tickers_list_transform_ = [i if i not in list_remove else False for i in _tickers]\n",
    "        self.tickers_list = [i for i in _tickers_list_transform_ if i]\n",
    "        \n",
    "list_of_symbols__ = ListSAndP500().tickers_list\n",
    "\n",
    "class YahooFinance:\n",
    "    def __init__(self, list_of_symbols, start, end):\n",
    "        self.schema = StructType([\n",
    "            StructField(column_1_name, StringType(), True),\n",
    "            StructField(column_2_name, StringType(), True),\n",
    "            StructField(column_3_name, StringType(), True),\n",
    "            StructField(column_4_name, StringType(), True),\n",
    "            StructField(column_5_name, StringType(), True),\n",
    "            StructField(column_6_name, StringType(), True),\n",
    "            StructField(column_7_name, StringType(), True),\n",
    "            StructField(column_8_name, StringType(), True)\n",
    "        ])\n",
    "\n",
    "        self.symbols = list_of_symbols\n",
    "        self.interval = '1d'\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.results = self.process_data()\n",
    "\n",
    "    def process_data(self):\n",
    "        \"\"\"\n",
    "        Process the historical stock data for the stock symbols\n",
    "        \"\"\"\n",
    "        data = self.get_data()\n",
    "        return self.transform_data(data)\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        Get historical stock data from Yahoo Finance API using yfinance library\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: A DataFrame containing historical stock data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = yf.download(\n",
    "                self.symbols,\n",
    "                start=self.start,\n",
    "                end=self.end,\n",
    "                interval=self.interval,\n",
    "                ignore_tz=True,\n",
    "                threads=5,\n",
    "                timeout=60,\n",
    "                progress=True\n",
    "            )\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading data: {e}\")\n",
    "            return None\n",
    "\n",
    "    def transform_data(self, df):\n",
    "        \"\"\"\n",
    "        Transform the historical stock data into a format that can be stored in a database FactPrices table\n",
    "\n",
    "        Args:\n",
    "        df (DataFrame): A DataFrame containing historical stock data\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: A DataFrame containing transformed historical stock data with the following columns:\n",
    "        - stock_id (str): The stock symbol\n",
    "        - date (str): The date of the stock data\n",
    "        - open (float): The opening price of the stock\n",
    "        - high (float): The highest price of the stock\n",
    "        - low (float): The lowest price of the stock\n",
    "        - close (float): The closing price of the stock\n",
    "        - volume (int): The volume of the stock\n",
    "        - adjusted_close (float): The adjusted closing price of the stock\n",
    "\n",
    "        \"\"\"\n",
    "        # Reset the index to turn the MultiIndex into columns\n",
    "        df = df.reset_index()\n",
    "\n",
    "        # Create a list to store transformed records\n",
    "        records = []\n",
    "\n",
    "        # Iterate over each row and stock symbol\n",
    "        for index, row in df.iterrows():\n",
    "            date = row[('Date', '')]\n",
    "            for stock in self.symbols:\n",
    "                try:\n",
    "                    record = {\n",
    "                        column_1_name: stock,\n",
    "                        column_2_name: date,\n",
    "                        column_3_name: row[('Open', stock)],\n",
    "                        column_4_name: row[('High', stock)],\n",
    "                        column_5_name: row[('Low', stock)],\n",
    "                        column_6_name: row[('Close', stock)],\n",
    "                        column_7_name: row[('Volume', stock)],\n",
    "                        column_8_name: row[('Adj Close', stock)]\n",
    "                    }\n",
    "                    records.append(record)\n",
    "                except KeyError as e:\n",
    "                    print(f\"KeyError: {e} for stock: {stock} on date: {date}\")\n",
    "\n",
    "        # Convert the list of records into a DataFrame\n",
    "        return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0cd6a5-3629-42ae-886d-03e872242276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  498 of 498 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  stock_id       date        open        high         low       close  \\\n",
      "0      MMM 2015-01-02  137.717392  138.026749  136.061874  137.173920   \n",
      "1      AOS 2015-01-02   28.309999   28.415001   27.775000   28.004999   \n",
      "2      ABT 2015-01-02   45.250000   45.450001   44.639999   44.900002   \n",
      "3     ABBV 2015-01-02   65.440002   66.400002   65.440002   65.889999   \n",
      "4      ACN 2015-01-02   89.669998   90.089996   88.430000   88.839996   \n",
      "\n",
      "      volume  adjusted_close  \n",
      "0  2531214.0       92.933594  \n",
      "1  1540200.0       24.154337  \n",
      "2  3216600.0       37.481434  \n",
      "3  5086100.0       44.314426  \n",
      "4  2021300.0       75.950943  \n"
     ]
    }
   ],
   "source": [
    "transformed_data = YahooFinance(list_of_symbols__, '2015-01-01', datetime.now().strftime('%Y-%m-%d')).results\n",
    "print(transformed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3613f13-de97-4dae-b6c7-2b7408806ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1185240"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transformed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c52b0a-1f7f-4ec8-b976-a691e8c49f8f",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94ecfc50-b102-4561-b691-51d14a717ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_dict = dict()\n",
    "fileroute=\"./dataset/\"\n",
    "fileroute_ticket=\"./dataset/tickets/\"\n",
    "transformed_data.to_csv(fileroute + \"Summary.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "for i in range(len(list_of_symbols__)):\n",
    "    filtered_data = transformed_data[transformed_data['stock_id'] == list_of_symbols__[i]]\n",
    "    filtered_data = filtered_data.reset_index()\n",
    "    total_data_dict[list_of_symbols__[i]] = filtered_data\n",
    "    filtered_data.to_csv(fileroute_ticket + list_of_symbols__[i] + \".csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85ff026-0996-47ca-ab1c-0d1552dd6936",
   "metadata": {},
   "source": [
    "## Checking the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd7367a7-8c9f-4a71-832b-26e0b3d469b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = pd.DatetimeIndex(transformed_data['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f3edde9-b968-47d2-8ad3-bf08f9f3870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1077\n",
      "   missing_dates\n",
      "0     2015-01-01\n",
      "1     2015-01-03\n",
      "2     2015-01-04\n",
      "3     2015-01-10\n",
      "4     2015-01-11\n",
      "5     2015-01-17\n",
      "6     2015-01-18\n",
      "7     2015-01-19\n",
      "8     2015-01-24\n",
      "9     2015-01-25\n",
      "10    2015-01-31\n",
      "11    2015-02-01\n",
      "12    2015-02-07\n",
      "13    2015-02-08\n",
      "14    2015-02-14\n",
      "15    2015-02-15\n",
      "16    2015-02-16\n",
      "17    2015-02-21\n",
      "18    2015-02-22\n",
      "19    2015-02-28\n",
      "3457\n"
     ]
    }
   ],
   "source": [
    "complete_dates = pd.date_range(start='2015-01-01', end=datetime.now().strftime('%Y-%m-%d'))\n",
    "\n",
    "missing_dates = complete_dates.difference(unique_dates)\n",
    "\n",
    "# Convert missing dates to a DataFrame for display\n",
    "missing_dates_df = pd.DataFrame(missing_dates, columns=['missing_dates'])\n",
    "\n",
    "print(len(missing_dates_df))\n",
    "print(missing_dates_df.head(20))\n",
    "print(len(complete_dates))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
